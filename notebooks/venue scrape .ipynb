{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76857819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "madison_garden = ('https://www.concertarchives.org/venues/madison-square-garden--4?page=REPLACE#concert-table')\n",
    "united_center = ('https://www.concertarchives.org/venues/united-center--2?page=REPLACE#concert-table')\n",
    "the_fillmore = ('https://www.concertarchives.org/venues/the-fillmore?page=REPLACE#concert-table')\n",
    "club_quattro = ('https://www.concertarchives.org/venues/club-quattro-074f58c1-a434-4e63-9efa-80dae7c28dda?page=REPLACE#concert-table')\n",
    "columbiahalle = ('https://www.concertarchives.org/venues/columbiahalle?page=REPLACE#concert-table')\n",
    "opera_house = ('https://www.concertarchives.org/venues/concert-hall-sydney-opera-house--4?page=REPLACE#concert-table')\n",
    "rock_city = ('https://www.concertarchives.org/venues/rock-city?page=REPLACE#concert-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a429d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Madison Square Garden', 'United Center', 'The Fillmore', 'Club Quattro', 'Columbiahalle', 'Concert Hall, Sydney Opera House', 'Rock City']\n",
    "location = ['New York, New York, United States', 'Chicago, Illinois, United States', 'Detroit, Michigan, United States', 'Osaka, Ōsaka, Japan', 'Berlin, Berlin, Germany', 'Sydney, New South Wales, Australia', 'Nottingham, England, United Kingdom']\n",
    "url = [madison_garden, united_center, the_fillmore, club_quattro, columbiahalle, opera_house, rock_city]\n",
    "country = ['America', 'America', 'America', 'Japan', 'Germany', 'Australia', 'United Kingdom']\n",
    "pages = [20, 11, 9, 1, 11, 4, 15]\n",
    "\n",
    "halls = {'name': name, 'location':location, 'url':url, 'country':country, 'pages':pages}\n",
    "halls_df = pd.DataFrame(halls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "halls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c16dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRequest (url):\n",
    "    req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    page_soup = BS(webpage, \"html.parser\")\n",
    "    str_page = page_soup.findAll(\"span\", class_=\"\")\n",
    "    inner_soup = BS(str(str_page), \"html.parser\")\n",
    "    spans = inner_soup.findAll(\"span\", class_=\"\")\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9887bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date(string, fuzzy=False):\n",
    "    try:\n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def CleanHTML(spans):\n",
    "    res = str(spans)\n",
    "    res = re.sub('<span>', '', res)\n",
    "    res = re.sub('</span>', '', res)\n",
    "    res = re.sub('<strong>', '', res)\n",
    "    res = re.sub('</strong>', '', res)\n",
    "    res = re.sub('<span class=\"\">', '', res)\n",
    "    res = re.sub('\\n', '', res)\n",
    "    res = re.sub('</a>', '', res)\n",
    "    res = re.split(\">\", res)[-1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9812f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = []\n",
    "artist = []\n",
    "venue = []\n",
    "location = []\n",
    "country = []\n",
    "\n",
    "main_index = 0\n",
    "#new_index = 0\n",
    "for index, row in halls_df.iterrows():\n",
    "    for x in range(row['pages']):\n",
    "        main_index += 1\n",
    "        time.sleep(1)\n",
    "        spans = GetRequest(row['url'].replace('REPLACE', str(main_index)))\n",
    "        #print(spans)\n",
    "        new_index = 0\n",
    "\n",
    "        for span in spans:\n",
    "            #print(span)\n",
    "            new_index += 1\n",
    "            if new_index == 1:\n",
    "                year += [(CleanHTML(span))] \n",
    "                #print(CleanHTML(span))\n",
    "            elif new_index == 2:\n",
    "                artist += [(CleanHTML(span))]\n",
    "                #print(CleanHTML(span))\n",
    "            elif new_index == 3:\n",
    "                #print(CleanHTML(span))\n",
    "                venue += [(CleanHTML(span)).replace('…', row['name'])]\n",
    "                #print(CleanHTML(span))\n",
    "            elif new_index == 4: \n",
    "                if is_date(CleanHTML(span)) == True:\n",
    "                    location.append(row['location'])\n",
    "                    year += [(CleanHTML(span))]\n",
    "                    new_index = 1\n",
    "                    country += [row['country']]\n",
    "                else:\n",
    "                    location += [(CleanHTML(span))]\n",
    "                    country += [row['country']]\n",
    "               # print(CleanHTML(span))\n",
    "                    new_index = 0\n",
    "            \n",
    "            \n",
    "    venues = pd.DataFrame(list(zip(year, artist, venue, location, country)), \n",
    "                               columns =['year', 'artist', 'venue', 'location', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c318b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "venues = venues.drop_duplicates(keep='last')\n",
    "\n",
    "venues\n",
    "\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c750b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#venues.to_csv('venues.csv')\n",
    "#venues.to_csv('C:/Users/natha/Documents/NSS/Projects/capstone_3/data/venues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab06c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
